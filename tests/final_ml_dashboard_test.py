#!/usr/bin/env python3
"""
Final comprehensive test for ML dashboard functionality
"""

import sys
import os
import time
sys.path.insert(0, 'src')

def test_everything():
    print("üöÄ Final ML Dashboard Comprehensive Test")
    print("=" * 60)
    
    try:
        # Test 1: ML Detector functionality
        print("1. Testing ML Detector Core Functionality...")
        from core.ml_detector import MLThreatDetector
        
        detector = MLThreatDetector(lambda x: print(f"‚úÖ Response: {x.get('level', 'Unknown')}"))
        detector.start_monitoring()
        print("   ‚úÖ ML detector initialized and monitoring started")
        
        # Test 2: Statistics before any activity
        print("\n2. Testing Initial Statistics...")
        initial_stats = detector.get_ml_statistics()
        print(f"   Model Loaded: {initial_stats.get('model_loaded', False)}")
        print(f"   Features: {initial_stats.get('model_features', 0)}")
        print(f"   Initial Predictions: {initial_stats.get('total_predictions', 0)}")
        
        # Test 3: Generate ML activity
        print("\n3. Generating ML Activity...")
        test_threats = [
            {
                'type': 'mass_modification',
                'severity': 'CRITICAL',
                'description': 'IRC ransomware test',
                'count': 30,
                'process_info': [(2222, 'ransomware.exe')],
                'network_info': {
                    'orig_port': 55000,
                    'resp_port': 6667,
                    'protocol': 'tcp',
                    'service': 'irc',
                    'duration': 3.0,
                    'orig_bytes': 150,
                    'resp_bytes': 400,
                    'conn_state': 'SF'
                }
            },
            {
                'type': 'mass_deletion',
                'severity': 'HIGH',
                'description': 'HTTP suspicious activity',
                'count': 20,
                'process_info': [(3333, 'malware.exe')],
                'network_info': {
                    'orig_port': 60000,
                    'resp_port': 80,
                    'protocol': 'tcp',
                    'service': 'http',
                    'duration': 1.2,
                    'orig_bytes': 300,
                    'resp_bytes': 1024,
                    'conn_state': 'SF'
                }
            }
        ]
        
        for i, threat in enumerate(test_threats, 1):
            print(f"   Processing threat {i}: {threat['description']}")
            detector.analyze_threat(threat)
            time.sleep(0.5)
        
        print("   ‚úÖ ML activity generated")
        
        # Test 4: Check updated statistics
        print("\n4. Testing Updated Statistics...")
        updated_stats = detector.get_ml_statistics()
        print(f"   Total Predictions: {updated_stats.get('total_predictions', 0)}")
        print(f"   Malicious Detected: {updated_stats.get('malicious_detected', 0)}")
        print(f"   High Confidence Alerts: {updated_stats.get('high_confidence_alerts', 0)}")
        print(f"   Average Confidence: {updated_stats.get('average_confidence', 0.0):.3f}")
        
        # Test 5: Check confidence distribution
        conf_dist = updated_stats.get('confidence_distribution', {})
        print(f"   Confidence Distribution - High: {conf_dist.get('high', 0)}, Medium: {conf_dist.get('medium', 0)}, Low: {conf_dist.get('low', 0)}")
        
        # Test 6: Check ML logs
        print("\n5. Testing ML Logs...")
        logs = detector.get_recent_ml_logs(limit=5)
        print(f"   Retrieved {len(logs)} log entries")
        if logs:
            latest = logs[-1]
            print(f"   Latest log: [{latest.get('level', 'INFO')}] {latest.get('message', 'No message')[:50]}...")
        
        # Test 7: Check persistent stats file
        print("\n6. Testing Persistent Stats...")
        stats_file = "logs/ml_stats.json"
        if os.path.exists(stats_file):
            with open(stats_file, 'r') as f:
                import json
                persistent_stats = json.load(f)
            print(f"   ‚úÖ Persistent stats file exists")
            print(f"   Persistent predictions: {persistent_stats.get('total_predictions', 0)}")
            print(f"   Persistent malicious: {persistent_stats.get('malicious_detected', 0)}")
        else:
            print("   ‚ùå Persistent stats file not found")
        
        # Test 8: Test GUI import (if available)
        print("\n7. Testing GUI Integration...")
        try:
            from ui.main_gui import ML_DETECTOR_AVAILABLE
            print(f"   ‚úÖ GUI ML_DETECTOR_AVAILABLE: {ML_DETECTOR_AVAILABLE}")
            
            if ML_DETECTOR_AVAILABLE:
                # Test GUI can get stats
                gui_detector = MLThreatDetector(lambda x: None)
                gui_stats = gui_detector.get_ml_statistics()
                print(f"   ‚úÖ GUI can access ML stats - Predictions: {gui_stats.get('total_predictions', 0)}")
            
        except ImportError as e:
            print(f"   ‚ö†Ô∏è GUI not available for testing: {e}")
        
        detector.stop_monitoring()
        
        print("\n" + "=" * 60)
        print("üéâ ALL TESTS COMPLETED SUCCESSFULLY!")
        print("üìä ML Dashboard Status:")
        print("   ‚úÖ ML detector working")
        print("   ‚úÖ Statistics tracking active")
        print("   ‚úÖ Persistent stats saving")
        print("   ‚úÖ ML logging operational")
        print("   ‚úÖ GUI integration ready")
        print("\nüöÄ READY FOR GUI TESTING:")
        print("   1. Run: python run_full_gui.py")
        print("   2. Go to 'ML Analytics' tab")
        print("   3. Check ML statistics and logs")
        print("   4. Statistics should show activity!")
        print("=" * 60)
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_everything()